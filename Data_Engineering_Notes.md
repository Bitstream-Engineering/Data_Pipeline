** Data Engineering **

Design systems that can:
1. Collect.
2. Process.
3. Transform.
4. Analyze     Data at scale.

Languages to learn - Python

Big data technologies:
1. Spark
2. Kafka
3. Flink
4. Beam


** Data pipelines **

Data producers -> Data pipelines -> Data consumers

We can use a process like:
1. ETL(Extract,Transform,Load).
2. Data Replication - Continuously copying and replication data into another repository before being loaded and used.
3. Data virtualization - Virtualizing access to our data sources and only query them in real time
when we need it without copying them over.

We need to use data pipelines tools to create high quality data for ML models.

